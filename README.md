# üêü Fish Weight Prediction - End-to-End MLOps

Este projeto √© uma solu√ß√£o completa de Machine Learning **para prever o peso de peixes com base em medidas f√≠sicas**. O objetivo foi demonstrar boas pr√°ticas de MLOps, desde a engenharia de dados at√© ao deploy de uma API escal√°vel e interface de utilizador.

## üèÜ Requisitos

### 1\. Python + Machine Learning (Obrigat√≥rio)

- **Modelo:** Utilizei **XGBoost Regressor**, escolhido pela sua performance em dados tabulares.
- **Separa√ß√£o:** Separa√ß√£o de responsabilidades em m√≥dulos Python:
  - `src/feature_pipeline`: Ingest√£o e limpeza.
  - `src/training_pipeline`: Treino e avalia√ß√£o.
  - `src/inference_pipeline`: L√≥gica de predi√ß√£o para produ√ß√£o.

### 2\. Pipeline de MLOps (Obrigat√≥rio)

- **Versionamento:** Integra√ß√£o completa com **MLflow** para registar par√¢metros, m√©tricas (MAE, RMSE, R¬≤) e artefatos do modelo (`.pkl`).
- **Orquestra√ß√£o:** Scripts organizados que podem ser executados individualmente ou encadeados via Makefile.

### 3\. Deploy em Container (Obrigat√≥rio)

- **API:** Desenvolvida em **FastAPI** para alta performance.
- **Docker:** A solu√ß√£o √© entregue containerizada. O Dockerfile constr√≥i um ambiente isolado com todas as depend√™ncias geridas pelo `uv`.

### 4\. Diferenciais Implementados (Opcionais)

- ‚úÖ **Testes Unit√°rios:** Cobertura de testes com `pytest` para garantir a integridade da API e do schema de dados.
- ‚úÖ **CI/CD:** Pipeline no GitHub Actions que roda testes e build autom√°tico a cada push.
- ‚úÖ **Makefile:** Automa√ß√£o de comandos complexos para facilitar a execu√ß√£o.
- ‚úÖ **Visualiza√ß√£o:** Aplica√ß√£o Fullstack com Streamlit para demonstra√ß√£o interativa.
- ‚úÖ **Model Registry:** Uso de **MLflow** para registrar e versionar oficialmente o modelo como `FishWeightPredictor`.

## üèó Arquitetura da Solu√ß√£o

O projeto est√° modularizado em diret√≥rios espec√≠ficos:

- **Feature Pipeline:** Ingest√£o, limpeza e transforma√ß√£o dos dados (`src/feature_pipeline`).
- **Training Pipeline:** Treino do modelo XGBoost com rastreamento via MLflow (`src/training_pipeline`).
- **Inference:** API REST (`src/api`) e l√≥gica de infer√™ncia (`src/inference_pipeline`).
- **Frontend:** Interface com Streamlit (`src/app.py`).
- **DevOps:** Configura√ß√µes de Docker, Makefile e CI/CD.

## üìÇ Estrutura do Projeto

```text
‚îú‚îÄ‚îÄ .github/workflows  # Pipeline de CI (Testes e Build)
‚îú‚îÄ‚îÄ data/              # Dados brutos e processados
‚îú‚îÄ‚îÄ models/            # Artefatos do modelo (.pkl)
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ api/           # C√≥digo da API (FastAPI)
‚îÇ   ‚îú‚îÄ‚îÄ feature_.../   # Scripts de processamento
‚îÇ   ‚îú‚îÄ‚îÄ training_.../  # Scripts de treino e tuning
‚îÇ   ‚îî‚îÄ‚îÄ app.py         # Frontend Streamlit
‚îú‚îÄ‚îÄ tests/             # Testes unit√°rios e de integra√ß√£o
‚îú‚îÄ‚îÄ Dockerfile         # Configura√ß√£o da imagem da API
‚îú‚îÄ‚îÄ Makefile           # Comandos r√°pidos de execu√ß√£o
‚îî‚îÄ‚îÄ pyproject.toml     # Depend√™ncias (gerenciado pelo uv)
```

## üöÄ Como Executar

### Pr√©-requisitos

- **Docker** (Recomendado para execu√ß√£o isolada)
- Ou **Python 3.11+** com `uv` instalado para execu√ß√£o local.

---

### Op√ß√£o 1: Via Docker (Recomendado)

Esta op√ß√£o sobe a API pronta para uso sem instalar nada no seu Python local.

**1. Construir e Rodar a API:**
Isso ir√° construir a imagem, remover containers antigos e iniciar a API na porta 8000.

```bash
make docker-auto
```

**2. MLflow**

O projeto utiliza MLflow n√£o apenas para rastreamento de m√©tricas, mas tamb√©m como **Model Registry**.

Para visualizar o cat√°logo de modelos:

1. Execute o comando de interface:

   ```bash
   make run-mlflow
   ```

2. Acesse a http://127.0.0.1:5000.

3. Clique na aba "Models" no topo da p√°gina.

4. Ver√° o modelo FishWeightPredictor com todas as suas vers√µes (v1, v2, etc.) e est√°gios de produ√ß√£o.

**3. Testar a API:**

- Acesse a documenta√ß√£o interativa (Swagger): [http://localhost:8000/docs](https://www.google.com/search?q=http://localhost:8000/docs)
- Ou veja a sec√ß√£o **"Como Realizar a Infer√™ncia"** abaixo.

---

### Op√ß√£o 2: Execu√ß√£o Local (Desenvolvimento)

Se preferir rodar os scripts manualmente:

**1. Instalar depend√™ncias:**

```bash
pip install uv
make install
```

**2. Treinar o Modelo:**
Executa o pipeline completo (Load -\> Preprocess -\> Feature Eng -\> Train). O modelo ser√° salvo em `models/xgb_model.pkl` e as m√©tricas registadas no MLflow.

```bash
make train
```

**3. Rodar a API:**

```bash
make run-api
```

**4. Rodar o Dashboard (Streamlit):**
Para visualizar uma interface gr√°fica amig√°vel:

```bash
make run-app
```

- Acesse em: [http://localhost:8501](https://www.google.com/search?q=http://localhost:8501)

## üì° Como Realizar a Infer√™ncia

A API aceita requisi√ß√µes POST no endpoint `/predict`.

**Exemplo de Payload (JSON):**

```json
[
  {
    "Species": "Perch",
    "Length1": 20.0,
    "Length2": 22.0,
    "Length3": 23.5,
    "Height": 5.5,
    "Width": 3.3
  }
]
```

**Comando cURL:**

```bash
curl -X 'POST' \
  'http://localhost:8000/predict' \
  -H 'Content-Type: application/json' \
  -d '[{"Species": "Perch", "Length1": 20.0, "Length2": 22.0, "Length3": 23.5, "Height": 5.5, "Width": 3.3}]'
```

**Resposta Esperada:**

```json
{
  "predictions": [245.32]
}
```

## üîÆ Poss√≠veis Melhorias

Pontos identificados para evolu√ß√£o futura do projeto:

- **Monitoriza√ß√£o de Drift:** Integra√ß√£o com EvidentlyAI para alertar se os peixes na infer√™ncia tiverem medidas muito diferentes do treino.
- **Deploy em Cloud:** Configura√ß√£o de deploy cont√≠nuo (CD) para AWS ECS ou Lambda utilizando Terraform.
- **Feature Store:** Para um cen√°rio com milh√µes de registos, implementar uma Feature Store (ex: Feast) para servir features pr√©-calculadas.
- **Autentica√ß√£o:** Adicionar camada de seguran√ßa (OAuth2) na API.

---

**Autor:** Lucas Paulo de Souza Navegante
**Cr√©ditos:** _anesriad/Regression_ML_EndtoEnd_ que foi o modelo base para este projeto.
**Data:** 04/12/2025
